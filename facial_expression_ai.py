# -*- coding: utf-8 -*-
"""facial-expression-AI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a6XDf5_Vr2PJijgReNL2nkifskYipX48
"""

!pip install mtcnn
from keras.models import load_model
import tensorflow as tf
import sys
import cv2
import os
import mtcnn
import numpy as np
import random
from PIL import Image
from numpy import asarray
from matplotlib import pyplot
from mtcnn.mtcnn import MTCNN
print(mtcnn.__version__)
print(sys.version)

#IMAGE LOADER FUNCTIONS
def load_single_image(filename):
    # load image from file
    image = Image.open(filename)
    # convert to RGB, if needed
    image = image.convert('RGB')
    # convert to array
    pixels = asarray(image)
    return pixels

def load_images_from_folder(folder):
    images = []
    for filename in os.listdir(folder):
        img = cv2.imread(os.path.join(folder,filename))
        if img is not None:
            images.append(img)
    return images

#images = load_images_from_folder('./images')

#FACE DETECTOR
#returns an array of pixels of the detected face
#no_face_sample = load_single_image("/content/drive/MyDrive/SentimentAnalysis/DATA/Images/323.jpg")
def detect_face(pixels):
  detector = MTCNN()
  results = detector.detect_faces(pixels)
  if len(results) == 0:
    image = Image.fromarray(pixels)
    image = image.resize((160, 160))
    return asarray(image)
  x1, y1, width, height = results[0]['box']
  # bug fix
  #implement loop
  x1, y1 = abs(x1), abs(y1)
  x2, y2 = x1 + width, y1 + height
  face = pixels[y1:y2,x1:x2]
  image = Image.fromarray(face)
  image = image.resize((160, 160))
  face_array = asarray(image)
  return face_array

def detectface_and_load(Filenames):
    images = []
    for filename in Filenames:
        img = load_single_image(filename)
        if img is not None:
            img = detect_face(img)
            images.append(img)
    return images

def mapper(lista, listb):
  assert len(lista) == len(listb)
  listc = []
  for i in range(len(listb)):
    listc.append([lista[i],listb[i]])
  return listc

def demapper(listc):
  lista = []
  listb = []
  for i in listc:
    lista.append(i[0])
    listb.append(i[1])
  return lista, listb

emotions = ["DISGUST", "HAPPINESS", "NEUTRAL", "ANGER", "SURPRISE", "SADNESS", "NOFACE"]

#LOAD TRAINED MODEL
#Unable to share training data, therefore loading trained model directly from mydrive
model = tf.keras.models.load_model('./bin')

def predictor(image_path):
  image = detect_face(load_single_image(image_path))
  image = asarray(image)/255.0

  #print image
  print(image.shape)
  #pyplot.subplot(2, 7,1)
  pyplot.axis('off')
  pyplot.imshow(image)
  pyplot.show()

  image = tf.constant([[image]])
  image = tf.data.Dataset.from_tensor_slices(image)
  results = model.predict(image)
  print("Classifier:\n")
  print(mapper(asarray(results[0]) * 100,emotions))
  print("Prediction = " + emotions[np.argmax(results[0])])
